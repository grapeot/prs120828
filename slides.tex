\documentclass[12pt]{beamer}
\author{Yan Wang}
\title{Paper Reading Seminar}
\subtitle{}
\usetheme{Malmoe}
\setbeamertemplate{navigation symbols}{}
\newcommand*\oldmacro{}%
\let\oldmacro\insertshorttitle%
\renewcommand*\insertshorttitle{%
\oldmacro\hfill%
\insertframenumber\,/\,\inserttotalframenumber}

\begin{document}

\begin{frame}[plain]
	\titlepage
\end{frame}

\begin{frame}{Kernel descriptors for visual recognition}
    \begin{itemize}
        \item Problem: a distance metric for various visual features
        \begin{itemize}
            \item Orientation histogram (HoG, SIFT)
            \item Color
            \item Texture (binary patterns)
        \end{itemize}
        \item Efficiency
    \end{itemize}
\end{frame}

\begin{frame}{Approach}
    \begin{itemize}
        \item Orientation histogram
        \begin{itemize}
            \item Input: orientation histogram of two patches $P$, $Q$
            \[ K_\text{grad}(P, Q) = \sum_{z \in P} \sum_{z' \in Q} \tilde{m} (z) \tilde{m}(z') k_o\big(\tilde{\theta}(z), \tilde{\theta}(z')\big) k_p(z, z') \]
            \item $\tilde{m}(z) \tilde{m}(z')$: magnitude of the gradient as weights
            \item $k_o, k_p$ are Gaussian kernels, $k_p(z, z') = \exp \big( -\gamma_p \lVert z - z' \rVert^2 \big) $
            \item $\tilde{\theta}(z) = [cos\big(\theta(z)\big), \sin\big(\theta(z)\big)]$. L2 distance $\Rightarrow$ difference of gradient orientations
            \item $k_p$ measures the differences of pixel positions (for SIFT)
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Approach}
    \begin{itemize}
        \item Color
            { \footnotesize \[ K_\text{color}(P, Q) = \sum_{z \in P} \sum_{z' \in Q} k_c\big(c(z), c(z')\big) k_p(z, z') \] }
        \item Shape
        { \footnotesize \[ K_\text{shape}(P, Q) = \sum_{z \in P} \sum_{z' \in Q} \tilde{s}(z) \tilde{s}(z') k_b\big(b(z), b(z')\big) k_p(z, z') \] }
        \begin{columns}
        \column{0.7\textwidth}
        \begin{itemize}
            \item $\tilde{s}(z) = s(z) / \sqrt{\sum_{z \in P} s(z)^2 + \epsilon_s}$
            \item $s(z)$: standard derivation of pixel values in the $3 \times 3$ pixels neighborhood
            \item $b(z)$: binary pattern of the neighborhood
        \end{itemize}
        \column{0.3\textwidth}
        \includegraphics[width=\textwidth]{kernel1.png}
        \end{columns}
    \end{itemize}
\end{frame}

\begin{frame}{Learning compact features}
    \begin{itemize}
        \item Kernel $k(x, y) = \psi(x)^T\psi(y)$
        \item Project to a low dimension space given bases $H = [\psi(z_1), \psi(z_2), ..., \psi(z_D)]$
        \item Compute the coefficients with close form solution
        \[ v_x^* = \arg \min_{v_x} \lVert \psi(x) - H v_x \rVert^2 \]
        \[ v_x^* = \big(H^TH\big)^{-1}\big(H^T\psi(x)\big) \]
        \item Approximate the kernel distance with the projection coefficient as the feature map
    \end{itemize}
\end{frame}

\begin{frame}{Learning compact features}
    \begin{itemize}
        \item How to get the basis?
        \begin{itemize}
            \item Uniform dense sampling (like LSH?) from the support region (feature space)
            \item Effective
        \end{itemize}
        \includegraphics[width=0.8\textwidth]{kernel2.png}
    \end{itemize}
\end{frame}

\begin{frame}{RGB-(D) Scene Labeling: Features and Algorithms}
	\begin{itemize}
		\item Problem: indoor scene, optical photo + depth image $\Rightarrow$ pixel-wise label \\
		\medskip
		\includegraphics[width=0.5\textwidth]{fig1.png} \\
		\item Evaluation: NYU Depth Dataset (13 categories), Stanford Background Dataset (8 categories, no depth info), Mean AP.
	\end{itemize}
\end{frame}

\begin{frame}{Intuition}
	\begin{itemize}
		\item Kernel Descriptor + Efficient Matching Kernel: pixel level features in different domains $\Rightarrow$ superpixel level feature
		\item Segmentation tree: different scales of superpixel
		\item Contextual refinement
	\end{itemize}
\end{frame}

\begin{frame}{Approach}
	\begin{itemize}
		\item Segmentation trees
		\begin{itemize}
			\item gPb: local + global contrast cues $\Rightarrow$ pixel-level probability-of-boundary map
			\item Extend to depth frames
			\item Linear fusion for RGB-D frames \\
            \[\text{gPb}_\text{rgbd} = (1 - \alpha) \cdot \text{gPb}_\text{rgb} + \alpha \cdot \text{gPb}_\text{d}\]
		\end{itemize}
		\item Feature design
		\begin{itemize}
			\item Gradient, color, local binary pattern, depth gradient, spin/surface normal, KPCA/self-similarity
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Approach}
	\begin{itemize}
		\item Kernel descriptors
		\begin{itemize}
			\item Intuition: pixel features $\Rightarrow$ superpixel
			\[F_\text{grad}^t = \sum_{z\in Z}\tilde{m}_zk_o(\tilde{\theta}_z, p_i)k_s(z, q_j)\]
            ($p_i, q_j$ are randomly sampled from the superpixel)
			\includegraphics[width=0.7\textwidth]{fig3.png} \\
			\item Use image gradient + spin/normal
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Approach}
	\begin{columns}[l]
		\column{0.7\textwidth}
			\begin{itemize}
			\item Classification
			\begin{itemize}
				\item Efficient Match Kernel for fixed-length features on superpixels
				\item Linear SVM
				\item Normalize on superpixel area ($A_s$)
				\[A_s / (\sum_{q\in Q_c}A_q)^p\]
			\end{itemize}
			\item Segmentation tree
				\begin{itemize}
					\item Different level ($t$) of segmentation tree $\Leftrightarrow$ different scale of superpixels \\
					\item Tree(s) = $\{f_{t, c}(s_t)\}, \any t, c$
				\end{itemize}
			\end{itemize}
		\column{0.3\textwidth}
			\includegraphics[width=\textwidth]{fig2.png}
	\end{columns}
\end{frame}

\begin{frame}{Approach}
	\begin{itemize}
		\item Segmentation tree
		\begin{itemize}
			\item Accumulate features along paths for better accuracy \\
			\medskip
			\includegraphics[width=0.5\textwidth]{fig4.png}
		\end{itemize}
		\item Superpixel MRF with gPb
		\begin{itemize}
			\item Data term: $-f_{c, t}$
			\item Smoothing term
			\[V_{s, r} = \beta \exp(-\gamma \cdot \text{gPb}_\text{rgbd}(s, r))\]
			\item Solve with graph-cut
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Interesting insights}
    \begin{itemize}
        \item Superpixel-level feature beats pixel-level feature + MRF
        \item High-dimensional features + Linear SVM pick up important features
        \item Segmentation hierarchy helps a lot
    \end{itemize}
\end{frame}

\end{document}
